import numpy as np
# Import various methods.
import beta
import bumblepuppy
import dllu
import greenberg
import iou
import randomforest
import transition
import iocaine
import markov
import tree

import beta_copycat
import bumblepuppy_copycat
import dllu_copycat
import greenberg_copycat
import iou_copycat
import randomforest_copycat
import transition_copycat
import iocaine_copycat
import markov_copycat
import tree_copycat

# Use Proportional Representation to find most favorable move.
def proportionalRepresentation(array_of_moves, array_of_won_rounds, array_of_lost_rounds):

    best_prob = -1
    best_move = None

    for index, move in enumerate(array_of_moves):
        prob = np.random.beta(array_of_won_rounds[index], array_of_lost_rounds[index])
        if prob > best_prob:
            best_move = move.item()
            best_prob = prob

    return best_move


def updateWonLostRounds(array_of_moves, opponent_move, array_won_rounds, array_lost_rounds):

    step_size = 3
    decay_rate = 1.1

    decay_won = (array_won_rounds - 1) / decay_rate + 1
    decay_lost = (array_lost_rounds - 1) / decay_rate + 1

    for index, move in enumerate(array_of_moves):
        if move == (opponent_move + 1) % 3:
            decay_won[index] += step_size
        elif move == (opponent_move + 2) % 3:
            decay_lost[index] += step_size
        else:
            decay_won[index] += step_size / 2
            decay_lost[index] += step_size / 2
    return decay_won, decay_lost

main_step = 0
main_method_steps = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                              0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
main_won_rounds = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
                            1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
main_lost_rounds = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                             1, 1, 1, 1, 1, 1, 1, 1, 1, 1])

def main(observation, configuration):
    global main_step
    global main_method_steps
    global main_won_rounds
    global main_lost_rounds
    # If not first step, update # of won round first.
    if main_step > 0:
        temp_win, temp_lost = updateWonLostRounds(main_method_steps, 
                                                      int(observation.lastOpponentAction), 
                                                      main_won_rounds, main_lost_rounds)
        main_won_rounds = temp_win
        main_lost_rounds = temp_lost

    # Compute moves generated by each method.
    step_random_forest = randomforest.random_forest_random(observation, configuration)
    step_transition = transition.transition_agent(observation, configuration)
    step_multi_armed = beta.multi_armed_bandit_agent (observation, configuration)
    step_dllu1 = dllu.run(observation, configuration)
    step_greenberg = greenberg.greenberg_agent(observation, configuration)
    step_IOU = iou.agent(observation, configuration)
    step_bumblepuppy = bumblepuppy.run(observation, configuration)
    step_iocaine = iocaine.iocaine_agent(observation, configuration)
    step_markov = markov.markov_agent(observation, configuration)
    step_tree = tree.agent(observation, configuration)

    if main_step > 0:
        observation.lastOpponentAction = step_random_forest
        step_copycat_randomforecast = randomforest_copycat.random_forest_random(observation, configuration)
        observation.lastOpponentAction = step_transition
        step_copycat_transition = transition_copycat.transition_agent(observation, configuration)
        observation.lastOpponentAction = step_multi_armed
        step_copycat_multi_armed = beta_copycat.multi_armed_bandit_agent (observation, configuration)
        observation.lastOpponentAction = step_dllu1
        step_copycat_dllu1 = dllu_copycat.run(observation, configuration)
        observation.lastOpponentAction = step_greenberg
        step_copycat_greenberg = greenberg_copycat.greenberg_agent(observation, configuration)
        observation.lastOpponentAction = step_IOU
        step_copycat_IOU = iou_copycat.agent(observation, configuration)
        observation.lastOpponentAction = step_bumblepuppy
        step_copycat_bumblepuppy = bumblepuppy_copycat.run(observation, configuration)
        observation.lastOpponentAction = step_iocaine
        step_copycat_iocaine = iocaine_copycat.iocaine_agent(observation, configuration)
        observation.lastOpponentAction = step_markov
        step_copycat_markov = markov_copycat.markov_agent(observation, configuration)
        observation.lastOpponentAction = step_tree
        step_copycat_tree = tree_copycat.agent(observation, configuration)
    else:
        step_copycat_randomforecast = randomforest_copycat.random_forest_random(observation, configuration)
        step_copycat_transition = transition_copycat.transition_agent(observation, configuration)
        step_copycat_multi_armed = beta_copycat.multi_armed_bandit_agent (observation, configuration)
        step_copycat_dllu1 = dllu_copycat.run(observation, configuration)
        step_copycat_greenberg = greenberg_copycat.greenberg_agent(observation, configuration)
        step_copycat_IOU = iou_copycat.agent(observation, configuration)
        step_copycat_bumblepuppy = bumblepuppy_copycat.run(observation, configuration)
        step_copycat_iocaine = iocaine_copycat.iocaine_agent(observation, configuration)
        step_copycat_markov = markov_copycat.markov_agent(observation, configuration)
        step_copycat_tree = tree_copycat.agent(observation, configuration)


    # Have all the moves in a np array.
    main_method_steps = np.array([step_random_forest, step_transition, step_multi_armed, step_dllu1, 
                                  step_greenberg, step_IOU, step_bumblepuppy, step_iocaine, 
                                  step_markov, step_tree, step_copycat_randomforecast, step_copycat_transition,
                                  step_copycat_multi_armed, step_copycat_dllu1, step_copycat_greenberg,
                                  step_copycat_IOU, step_copycat_bumblepuppy, step_copycat_iocaine,
                                  step_copycat_markov, step_copycat_tree])

    # If not first step, find current optimized step.
    if main_step > 0:
        selected_step = proportionalRepresentation(main_method_steps, main_won_rounds, 
                                                   main_lost_rounds)
        main_step += 1
        return selected_step
    # Otherwise, return random number.
    else:
        main_step += 1
        return np.random.randint(3)